**课程名称**：编译原理与技术实践
**实验日期**：2026年01月13日

实践亮点：
1. 在 语法分析与符号管理 模块中，采用了 **Trie树与Hash的双向映射架构**，实现了内部分析阶段 $O(1)$ 的查表效率（单字节别名）与交互阶段的可读性还原（完整Token），平衡了性能与易用性。(2、4)
2. 在 语法分析器实现 中，采用了 **自动化表生成技术**，编写了 `maker.cpp` 生成器，实现了从文法产生式到 First/Follow 集推导、DFA 状态机构建及 SLR 分析表的自动生成，并进一步实现了 **分析表的代码自动生成**（直接导出为 C++ 头文件），消除了运行时建表的开销。(3)
3. 在 错误处理环节 中，设计了 **多层次错误恢复机制**（包括恐慌模式、虚拟插入与前瞻验证），特别是在 LR 分析中引入了 `isCandidateValid` **深度前瞻验证逻辑**，通过模拟后续解析步骤来验证插入符号的有效性，彻底解决了传统错误恢复中的“假阳性”与双重报错问题。(2、3)
4. 在 词法与语法分析 阶段，采用了 **确定性有限自动机 (DFA)** 与 **预测分析表驱动架构**，分别实现了基于状态迁移的复杂 Token 识别（如科学计数法）和无回溯的高效语法解析。(1、2)
5. 在 语法树可视化 模块中，结合了 **Graphviz DOT 语言**，开发了 `Visualizer.h` 模块，实现了 AST（抽象语法树）的自动序列化与图形化展示，能够直观对比自顶向下（LL）与自底向上（LR）的建树过程差异。(2、3)
6. 在 语义分析 阶段，采用了 **解释器模式与中间代码生成并行** 的策略，在生成四元式（IR）的同时维护符号表状态，实现了变量值的实时计算与类型自动提升（Type Promotion），并支持符号表快照（CSV）导出功能。(4)
7. 在 错误定位环节 中，设计了 **精确行号追踪机制**（`lastTokenLine` / `lastAcceptedTokenLine`），通过记录上一个成功匹配的 Token 位置，解决了在存在空行或跨行语句时错误报告行号滞后的常见问题，实现了语法错误的精准定位。(2、3)
8. 在 测试与验证 阶段，编写了 **自动化测试流水线**（`run_tests.py`），实现了测试用例的批量执行、结果自动比对、可视化文件生成及全流程报告导出，大幅提升了回归测试效率。(1、2、3、4)
9. 在 数据存储与优化 模块中，采用了 **双缓冲区读取** 与 **哈希表符号管理**，优化了文件读取性能，并支持了混合类型运算的兼容性处理。(4)
10. 在 项目架构设计 中，采用了 **模块化与流水线设计**，将词法、语法（LL/LR）、语义分析解耦为独立模块，既支持单独调试，又能通过统一接口组合成完整的编译流水线。(1、2、3、4)
